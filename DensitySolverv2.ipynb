{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jslon\\anaconda3\\Lib\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"16\"  # Set 16 threads for OpenBLAS\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"16\"  # Set 16 threads for OpenBLAS\n",
    "\n",
    "from findiff.operators import FinDiff, Identity, Coef\n",
    "from findiff.pde import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import cupy as cp\n",
    "from cupyx.scipy.sparse import csr_matrix as csr_gpu_matrix\n",
    "from cupyx.scipy.sparse import coo_matrix as coo_matrix_real\n",
    "from scipy.sparse import csr_matrix as csr_matrix_cpu\n",
    "from scipy.sparse.linalg import spsolve\n",
    "from cupyx.scipy.sparse import diags\n",
    "from cupyx.scipy.sparse.linalg import LinearOperator, cg, spilu, gmres\n",
    "import time as timer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Space Grid\n",
    "rmin = 1e-6\n",
    "rmax = 1.1\n",
    "nr = 50\n",
    "r, dr = np.linspace(rmin, rmax, nr, retstep = True)\n",
    "\n",
    "#Time Grid\n",
    "tmin = 2.9\n",
    "tmax = 4.0\n",
    "nt = 1000\n",
    "time, dt = np.linspace(tmin, tmax, nt, retstep = True)\n",
    "\n",
    "#Number of Samples\n",
    "iterations = 10000\n",
    "\n",
    "#Files\n",
    "Input_File = 'ProfileDataset622v2.pickle'\n",
    "Output_File = 'SolvedDataset622v2.pickle'\n",
    "\n",
    "#Flags\n",
    "save = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix Creation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def M1_Create(nr=50, nt=1000, dt=1):\n",
    "    '''Docstring WIP'''\n",
    "    #Define Matrix Size\n",
    "    N = nr*nt\n",
    "    \n",
    "    #Define Scaling Constant\n",
    "    a = 1/(2*dt)\n",
    "    \n",
    "    #Second Matrix\n",
    "    err_rows1 = cp.concatenate([cp.arange(0,nr,1), cp.repeat(cp.arange(0,N,1),2), cp.arange(N-nr,N,1)])\n",
    "    err_cols1 = cp.concatenate([cp.arange(0,nr,1), cp.tile(cp.array([nr,2*nr]),nr) + cp.repeat(cp.arange(0,nr,1),2), cp.tile(cp.array([0,nr*2]),N-2*nr) + cp.repeat(cp.arange(0,N-2*nr,1),2), cp.tile(cp.array([N-3*nr,N-2*nr]),nr) + cp.repeat(cp.arange(0,nr,1),2), cp.arange(N-nr,N,1)])\n",
    "    err_vals1 = a*cp.concatenate([-3*cp.ones(nr), cp.tile(cp.array([4,-1]), nr), cp.tile(cp.array([-1,1]), N-2*nr), cp.tile(cp.array([1,-4]), nr), 3*cp.ones(nr)])\n",
    "    coo_extra1 = coo_matrix_real((err_vals1, (err_rows1, err_cols1)), shape=(N, N))\n",
    "    \n",
    "    return coo_extra1.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def M2_Create(nr=50, nt=1000, dr=1, C=1):\n",
    "    '''Docstring WIP'''\n",
    "    #Define Matrix Size\n",
    "    N = nr*nt\n",
    "    \n",
    "    #Define Scaling Constant\n",
    "    a0 = 1/(dr**2)\n",
    "    a1 = a0*cp.array(cp.array(C.ravel()))\n",
    "    \n",
    "    #Create diagonal values directly on the GPU\n",
    "    main_diag = a1*cp.concatenate([cp.array([2]), -2*cp.ones(N - 2), cp.array([2])])\n",
    "    upper_diag = a1[:-1]*cp.concatenate([cp.array([-5]), cp.ones(N - 2)])\n",
    "    lower_diag = a1[1:]*cp.concatenate([cp.ones(N - 2), cp.array([-5])])\n",
    "    \n",
    "    #Formatting\n",
    "    diagonals = [main_diag, upper_diag, lower_diag]\n",
    "    offsets = [0, 1, -1]\n",
    "    \n",
    "    # Create a diagonal sparse matrix\n",
    "    csr_gpu1 = diags(diagonals, offsets, format='csr')\n",
    "    \n",
    "    #Second Matrix\n",
    "    err_rows1 = cp.sort(cp.concatenate([cp.tile(cp.concatenate([cp.arange(nr,N,nr), cp.arange(nr-1,N-1,nr)]),4),cp.array([0,0,N-1,N-1])])) #Optimize cp.repeat()?\n",
    "    err_cols1 = cp.concatenate([cp.array([2,3]), cp.repeat(cp.arange(nr-4,N-nr-3,nr),8) + cp.tile(cp.array([0,1,2,3,4,5,6,7]),nt-1), cp.array([N-4,N-3])]) #Optimize, No comprehension\n",
    "    err_vals1 = a1[err_rows1]*cp.concatenate([cp.array([4,-1]), cp.tile(cp.array([-1,4,-6,4,4,-6,4,-1]),nt-1), cp.array([-1,4])])\n",
    "    coo_extra1 = coo_matrix_real((err_vals1, (err_rows1, err_cols1)), shape=(N, N))\n",
    "    \n",
    "    #Third Matrix\n",
    "    err_rows2 = cp.sort(cp.concatenate([cp.arange(nr-1,N-1,nr), cp.arange(nr,N,nr)]))\n",
    "    err_cols2 = cp.vstack((cp.arange(nr,N-nr+1,nr), cp.arange(nr-1,N-nr,nr))).T.ravel()\n",
    "    err_vals2 = -a1[err_rows2]*cp.ones(2*nt-2)\n",
    "    coo_extra2 = coo_matrix_real((err_vals2, (err_rows2, err_cols2)), shape=(N, N))\n",
    "    \n",
    "    csr_gpu = csr_gpu1 + coo_extra1.tocsr() + coo_extra2.tocsr()\n",
    "    \n",
    "    return csr_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def M3_Create(nr=50, nt=10000, dr=1, C=1):\n",
    "    '''Docstring WIP'''\n",
    "    #Define Matrix Size\n",
    "    N = nr*nt\n",
    "    \n",
    "    #Define Scaling Constant\n",
    "    a0 = 1/(2*dr)\n",
    "    a1 = a0*cp.array(C.ravel())\n",
    "    \n",
    "    #Create diagonal values directly on the GPU\n",
    "    main_diag = a1*cp.concatenate([cp.array([-3]), cp.zeros(N-2), cp.array([3])])\n",
    "    upper_diag = a1[:-1]*cp.concatenate([cp.array([4]), cp.ones(N-2)])\n",
    "    lower_diag = a1[1:]*cp.concatenate([-cp.ones(N-2), cp.array([-4])])\n",
    "    \n",
    "    #Formatting\n",
    "    diagonals = [main_diag, upper_diag, lower_diag]\n",
    "    offsets = [0, 1, -1]\n",
    "    \n",
    "    # Create a diagonal sparse matrix\n",
    "    csr_gpu1 = diags(diagonals, offsets, format='csr')\n",
    "    \n",
    "    #Second Matrix\n",
    "    rows = cp.concatenate([cp.array([0,N-1]), cp.repeat(cp.arange(nr-1,N-nr,nr),4), cp.repeat(cp.arange(nr,N-nr+1,nr),4)])\n",
    "    cols = cp.concatenate([cp.array([2,N-3]), cp.repeat(cp.arange(nr-1,N-nr,nr),4) + cp.tile(cp.array([-2,-1,0,1]),nt-1), cp.repeat(cp.arange(nr,N-nr+1,nr),4) + cp.tile(cp.array([0,1,2,-1]),nt-1)])\n",
    "    values = a1[rows]*cp.concatenate([cp.array([-1,1]), cp.tile(cp.array([1,-3,3,-1]),nt-1), cp.tile(cp.array([-3,3,-1,1]),nt-1)])\n",
    "    coo_extra = coo_matrix_real((values, (rows, cols)), shape=(N, N))\n",
    "    \n",
    "    csr_gpu = csr_gpu1 + coo_extra.tocsr()\n",
    "    \n",
    "    return csr_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def M4_Create(nr=50, nt=10000, C=1):\n",
    "    '''Docstring WIP'''\n",
    "    #Define Matrix Size\n",
    "    N = nr*nt\n",
    "    \n",
    "    #Define Scaling Constant\n",
    "    a1 = cp.array(C.ravel())\n",
    "    \n",
    "    #Create diagonal values directly on the GPU\n",
    "    main_diag = a1*cp.ones(N)\n",
    "    \n",
    "    # Create a diagonal sparse matrix\n",
    "    csr_gpu = diags(main_diag, 0, format='csr')\n",
    "    \n",
    "    return csr_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MBCL_Create(nr=50, nt=1000, dr=1):\n",
    "    '''Docstring WIP'''\n",
    "    #Define Matrix Size\n",
    "    N = nr*nt\n",
    "    a = 1/(2*dr)\n",
    "    Rows1 = cp.concatenate([cp.arange(1,nr,1), cp.arange(2*nr-1,N,nr), cp.repeat(cp.arange(0,N,nr),3)])\n",
    "    Cols1 = cp.concatenate([cp.arange(1,nr,1), cp.arange(2*nr-1,N,nr), cp.repeat(cp.arange(0,N,nr),3) + cp.tile(cp.array([0,1,2]),nt)])\n",
    "    Vals1 = cp.concatenate([cp.ones(nt+nr-2), a*cp.tile(cp.array([-3,4,-1]),nt)])\n",
    "    M1 = coo_matrix_real((Vals1, (Rows1, Cols1)), shape=(N, N)).tocsr()\n",
    "    return M1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MBCR_Create(nr=50, nt=1000, CMBCR=1):\n",
    "    #Define Matrix Size\n",
    "    N = nr*nt\n",
    "    Rows2 = cp.concatenate([cp.arange(1,nr,1), cp.arange(2*nr-1,N,nr)])\n",
    "    Cols2 = cp.zeros(nt+nr-2)\n",
    "    Vals2 = cp.concatenate([cp.array(CMBCR[1:]),CMBCR[-1]*cp.ones(nt-1)])\n",
    "    M2 = coo_matrix_real((Vals2, (Rows2, Cols2)), shape=(N, 1)).tocsr()\n",
    "    return M2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReadPickle(filename: str) -> dict:\n",
    "  '''Reads in data from given pickle files, outputs a dictionary'''\n",
    "  try:\n",
    "    Data = pd.read_pickle(filename)\n",
    "  except FileNotFoundError:\n",
    "    raise FileNotFoundError(f'Error reading {filename}')\n",
    "  return Data\n",
    "def convert_seconds(seconds):\n",
    "    hours = int(seconds // 3600)\n",
    "    minutes = int((seconds % 3600) // 60)\n",
    "    secs = seconds % 60\n",
    "    return hours, minutes, secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PDE_v2(object):\n",
    "    def __init__(self, lhs, rhs, bcsL, bcsR):\n",
    "        self.lhs = lhs\n",
    "        #self.lhs.matrix = profile(self.lhs.matrix)\n",
    "        #self.lhs.left.matrix = profile(self.lhs.left.matrix)\n",
    "        self.rhs = rhs\n",
    "        self.bcsL = bcsL\n",
    "        self.bcsR = bcsR\n",
    "        self._L = None\n",
    "        \n",
    "    def solve_v2(self):\n",
    "        shape = self.rhs.shape\n",
    "        if self._L is None:\n",
    "            self._L = self.lhs # expensive operation\n",
    "            \n",
    "        L_GPU = self._L\n",
    "        bcs_lhs_gpu = self.bcsL\n",
    "\n",
    "\n",
    "        f = cp.array(self.rhs.reshape(-1, 1))\n",
    "\n",
    "        nz = self.bcsL.tocoo().row\n",
    "\n",
    "        L_GPU[nz, :] = bcs_lhs_gpu[nz, :]\n",
    "\n",
    "        f[nz] = cp.array(self.bcsR[nz].toarray()).reshape(-1, 1)\n",
    "\n",
    "        L = L_GPU.get()\n",
    "        u = spsolve(L, cp.asnumpy(f)).reshape(shape)\n",
    "        return u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = 2 # global FinDiff numerical accuracy order\n",
    "\n",
    "#Differential Operators\n",
    "d_dr = FinDiff(1, r, 1, acc = acc)\n",
    "d2_dr2 = FinDiff(1, r, 2, acc = acc)\n",
    "\n",
    "shape = (len(time), len(r)) # (1000,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FinalBuilder(nr, nt, r, dr, time, dt, SRin, STin, Din, Vin, N0in):\n",
    "    '''Docstring WIP'''\n",
    "    SGrid = np.outer(STin, SRin)\n",
    "    DGrid = np.outer(np.ones(len(time)), Din)\n",
    "    VGrid = np.outer(np.ones(len(time)), Vin)\n",
    "\n",
    "    gradD = d_dr(DGrid)\n",
    "    gradv = d_dr(VGrid)\n",
    "\n",
    "    BLinear = (gradD - VGrid)\n",
    "    CM3 = BLinear + DGrid/r\n",
    "    CM4 = gradv + VGrid/r\n",
    "\n",
    "    M1m = M1_Create(nr=nr, nt=nt, dt=dt)\n",
    "    M2m = M2_Create(nr=nr, nt=nt, dr=dr, C=DGrid)\n",
    "    M3m = M3_Create(nr=nr, nt=nt, dr=dr, C=CM3)\n",
    "    M4m = M4_Create(nr=nr, nt=nt, C=CM4)\n",
    "    MFm = M1m - M2m - M3m + M4m\n",
    "\n",
    "    BCL = MBCL_Create(nr=nr, nt=nt, dr=dr)\n",
    "    BCR = MBCR_Create(nr=nr, nt=nt, CMBCR=N0in)\n",
    "\n",
    "    pde = PDE_v2(MFm.copy(), SGrid.copy(), BCL.copy(), BCR.copy())\n",
    "    u = pde.solve_v2()\n",
    "    return u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Solver\n",
      "Solver Finished\n",
      "Total Time Taken: 1hr 11min 23.124s\n",
      "Time Per Iteration: 0.42831s\n"
     ]
    }
   ],
   "source": [
    "data_in = ReadPickle(Input_File)\n",
    "data_out = []\n",
    "\n",
    "print('Starting Solver')\n",
    "t1 = timer.time()\n",
    "for i in range(iterations):\n",
    "    Dict_in = data_in[i]\n",
    "    SRin, STin, Din, Vin, N0in = Dict_in['SR'], Dict_in['ST'], Dict_in['D'], Dict_in['V'], Dict_in['N0']\n",
    "    N = FinalBuilder(nr, nt, r, dr, time, dt, SRin, STin, Din, Vin, N0in)\n",
    "    Dict_Out = {'N':N,'D':Din,'V':Vin, 'SR':SRin, 'ST':STin,'N0':N0in}\n",
    "    data_out.append(Dict_Out)\n",
    "if save:\n",
    "    with open(Output_File, 'wb+') as f:\n",
    "        # Pickle the 'data' dictionary using the highest protocol available.\n",
    "        pickle.dump(data_out, f, pickle.HIGHEST_PROTOCOL)\n",
    "t2 = timer.time()\n",
    "print('Solver Finished')\n",
    "\n",
    "delta_t = t2 - t1\n",
    "hrs, mins, secs = convert_seconds(delta_t)\n",
    "print(f\"Total Time Taken: {hrs}hr {mins}min {np.round(secs,3)}s\")\n",
    "print(f\"Time Per Iteration: {np.round((delta_t)/iterations,5)}s\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Boundary Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Diagnose = 0\n",
    "if Diagnose:\n",
    "        SGrid = np.outer(np.ones(len(time)), Sin)\n",
    "        DGrid = np.outer(np.ones(len(time)), Din)\n",
    "        VGrid = np.outer(np.ones(len(time)), Vin)\n",
    "\n",
    "        gradD = d_dr(DGrid)\n",
    "        gradv = d_dr(VGrid)\n",
    "\n",
    "        BLinear = (gradD - VGrid)\n",
    "        CM3 = BLinear + DGrid/r\n",
    "        CM4 = gradv + VGrid/r\n",
    "\n",
    "        M1m = M1_Create(nr=nr, nt=nt, dt=dt)\n",
    "        M2m = M2_Create(nr=nr, nt=nt, dr=dr, C=DGrid)\n",
    "        M3m = M3_Create(nr=nr, nt=nt, dr=dr, C=CM3)\n",
    "        M4m = M4_Create(nr=nr, nt=nt, C=CM4)\n",
    "        MFm = M1m - M2m - M3m + M4m\n",
    "        \n",
    "        L = ( FinDiff(0, time, 1, acc = acc) \n",
    "                - Coef(DGrid)*FinDiff(1, r, 2, acc = acc)\n",
    "                - Coef(BLinear + DGrid/r)*FinDiff(1, r, 1, acc = acc)\n",
    "                + Coef(gradv + VGrid/r)*Identity() ) \n",
    "        MFt = L.matrix(shape)\n",
    "        M1t = FinDiff(0, time, 1, acc = acc).matrix(shape)\n",
    "        M2t = (Coef(DGrid)*FinDiff(1, r, 2, acc = acc)).matrix(shape)\n",
    "        M3t = (Coef(BLinear + DGrid/r)*FinDiff(1, r, 1, acc = acc)).matrix(shape)\n",
    "        M4t = (Coef(gradv + VGrid/r)*Identity()).matrix(shape)\n",
    "        \n",
    "        MDf = np.abs(MFm - csr_gpu_matrix(MFt))\n",
    "        MD1 = np.abs(M1m - csr_gpu_matrix(M1t))\n",
    "        MD2 = np.abs(M2m - csr_gpu_matrix(M2t))\n",
    "        MD3 = np.abs(M3m - csr_gpu_matrix(M3t))\n",
    "        MD4 = np.abs(M4m - csr_gpu_matrix(M4t))\n",
    "        \n",
    "        print(f\"Total Real: {np.abs(MFt).sum()}\")\n",
    "        print(f\"Total Calc: {np.abs(MFm).sum()}\")\n",
    "        print('')\n",
    "        print(f\"Total Diff: {MDf.sum()}\")\n",
    "        print(f\"Diff Term1: {MD1.sum()}\")\n",
    "        print(f\"Diff Term2: {MD2.sum()}\")\n",
    "        print(f\"Diff Term3: {MD3.sum()}\")\n",
    "        print(f\"Diff Term4: {MD4.sum()}\")\n",
    "        print(f\"Diff Ratio: {MDf.sum()/np.abs(MFt).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Check = 0\n",
    "total_diff = 0\n",
    "total = 0\n",
    "if Check:\n",
    "    data_vals = ReadPickle('Solved_Dataset_3.pickle')\n",
    "    for i in range(iterations):\n",
    "        N = data_vals[i]['N']\n",
    "        total += np.abs(N).sum()\n",
    "        diff = np.abs(N - data_out[i]).sum()\n",
    "        total_diff += diff\n",
    "    print(f\"Average Diff: {total_diff/iterations}\")\n",
    "    print(f\"Ratio Diff: {total_diff/total}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
